# Copyright (c) 2020 Ryuichi Yamamoto
# Copyright (c) 2020 oatsu

# Is trained with ENUNU specific recipe
trained_for_enunu:      true
# Table (lyric -> phonemes) file path.
table_path:             dic/kana2phonemes_001_oto2lab.table
# bit depth of output wav file.
# 32 or 16 (recommended:32)
bit_depth:              32

defaults:
    - hydra/job_logging: colorlog
    - hydra/hydra_logging: colorlog

verbose:                100

# Setting for output WAV file.
sample_rate:            44100
gain_normalize:         false

# How was the model trained.
frame_period:           5
question_path:          hed/jp_qst_crazy_mono_012_enunu_212D.hed
log_f0_conditioning:    true

# Use ground truth duration or not
# if true, time-lag and duration models will not be used.
ground_truth_duration:  false


# If not empty, try to search statisics in the directory
stats_dir:              dump/unnamed/norm
# If not empty, try to search models in the directory
model_dir:              exp/unnamed_enunu_train_kit

acoustic:
    question_path:      null
    checkpoint:         best_loss.pth
    in_scaler_path:     null
    out_scaler_path:    null
    # model_yaml:
    subphone_features:  coarse_coding
    relative_f0:        true
    post_filter:        true

duration:
    checkpoint:         best_loss.pth
    question_path:      null
    in_scaler_path:     null
    out_scaler_path:    null

timelag:
    question_path:      null
    checkpoint:         best_loss.pth
    in_scaler_path:     null
    out_scaler_path:    null
    allowed_range:      [-20, 19]
    allowed_range_rest: [-40, 39]
